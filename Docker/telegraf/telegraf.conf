[agent]
  interval = "1s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "1s"
  flush_jitter = "0s"
  precision = ""
  debug = false
  quiet = false
  logfile = ""
  hostname = ""
  omit_hostname = false

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

[[outputs.influxdb]]
  urls = ["http://influxdb:8086"] # required
  database = "beam" # required
  retention_policy = ""
  write_consistency = "any"
  timeout = "5s"
   namedrop = ["pageviews_time_spent"]

 # measurement for collecting time spent has own retention policy
 [[outputs.influxdb]]
   urls = ["http://influxdb:8086"] # required
   database = "beam" # required
   retention_policy = "timespent_rp"
   write_consistency = "any"
   timeout = "5s"
   namepass = ["pageviews_time_spent"]

[[outputs.remp_elasticsearch]]
  urls = ["http://elasticsearch:9200"] # required
  timeout = "5s"
  index_name = "pageviews"
  type_name = "_doc"
  namepass = ["pageviews"]
  manage_template = false
  id_field = "remp_pageview_id"
  tagexclude = ["host"]

[[outputs.remp_elasticsearch]]
  urls = ["http://elasticsearch:9200"] # required
  timeout = "5s"
  index_name = "pageviews_time_spent"
  type_name = "_doc"
  namepass = ["pageviews_time_spent"]
  manage_template = false
  id_field = "remp_pageview_id"
  updated_fields = ["timespent"]
  tagexclude = ["host"]

[[outputs.remp_elasticsearch]]
  urls = ["http://elasticsearch:9200"] # required
  timeout = "5s"
  index_name = "events"
  type_name = "_doc"
  namepass = ["events_v2"]
  manage_template = false
  id_field = "remp_event_id"
  tagexclude = ["host"]

[[outputs.remp_elasticsearch]]
  urls = ["http://elasticsearch:9200"] # required
  timeout = "5s"
  index_name = "commerce"
  type_name = "_doc"
  namepass = ["commerce"]
  manage_template = false
  id_field = "remp_commerce_id"
  tagexclude = ["host"]

[[outputs.remp_elasticsearch]]
  urls = ["http://elasticsearch:9200"] # required
  timeout = "5s"
  index_name = "concurrents"
  type_name = "_doc"
  namepass = ["pageviews_time_spent"]
  manage_template = false
  taginclude = ["remp_session_id", "time", "article_id", "browser_id", "remp_pageview_id", "author_id", "category", "tags", "token"]
  id_field = "remp_session_id"
  updated_fields = ["time", "article_id"]

###############################################################################
#                            SERVICE INPUT PLUGINS                            #
###############################################################################

[[inputs.kafka_consumer]]
  topics = ["beam_events"]
  brokers = ["kafka:9092"]
  consumer_group = "beam_consumers"
  offset = "oldest"
  data_format = "influx"